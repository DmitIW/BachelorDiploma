\usepackage{amsmath}
\usepackage{cleveref}

% В этом файле следует писать текст работы, разбивая его на
% разделы (section), подразделы (subsection) и, если нужно,
% главы (chapter).

% Предварительно следует указать необходимую информацию
% в файле SETUP.tex

\input{preamble.tex}

\begin{document}

\Intro

В рамках данной работы освещается вопрос семантического анализа изображений путем применения глубоких сверточных нейронных сетей.
Под семантическим анализом понимается получение из изображения какой-либо интерпретируемой информации: расположение объектов на сцене,
принадлежность объектов к заранее заданным классам, наличие на изображении объектов определённого типа и т.п..
Данная тема будет рассмотрена на примере задачи обнаружения и выделения неба на изображениях.
Входными данными задачи являются фотографии, сделанные на камеры мобильных устройств.
Специализированный домен изображений был выбран с целью упрощения адаптация потенциального решения к применению в конечных продуктах,
таких как пользовательское программное обеспечение для смартфонов.
Решением задачи выступают сгенерированные для входных фотографий полутоновые изображения.
Такое изображение называется сегментационной маской и для каждого пикселя исходной фотографии выражает его принадлежность
к региону неба: белый цвет интерпретируется как положительный результат, черный - как отрицательный.
В ходе разработки алгоритма решения задачи была исследована эффективность применения различных подходов к генерации подобного рода масок - сегментации.
Сравнения эффективности проходило по индексу Жаккара - в западной литературе также встречается название intersection over union, IoU\@.
Для решения задачи сегментации из наиболее эффективных подходов был составлен стек алгоритмов: применение к входному изображению глубокой сверточной сети
с последующей корректировкой методами компьютерного зрения полученной маски.
В ходе обучения модели искусственной нейронной сети, ИНС, для предотвращения переобучения и улучшения сходимости
применялись техники регуляризации, такие как learning rate reduce и one cycle policy.
Влияние данных подходов на решение также отражено в результатах работы.
В заключительной части хода разработки была рассмотрена возможность адаптация модели, обученной на данных датасета SkyFinder,
к выбранному домену изображений.
Данная техника имеет название Domain Adaptation и используется для улучшения качества на практических данных.

% Если typeOfWork в SETUP.tex задан как 2 или 3, то начинать
% надо не с section (раздел), а с главы (chapter)

\section{Постановка и описание задачи}

Цифровая обработка изображений являются комплексной темой.
В нее входят задачи фильтрации, преобразования цвета, яркости и контрастности,
морфологической обработка, распознавания и выделения объектов на сцене~\autocite{gonzalez2008digital}.
Семантический анализу - подход, целью которого является получение интерпретируемой информации высших порядков об изображении.
К подзадачам семантического анализа можно отнести классификацию объектов на сцене, детекцию объектов и сегментацию изображений на семантические регионы.
В рамках текущей работы будет проведен разбор подзадачи сегментации.

\subsection{Задача сегментации}

Для возможности цифровой обработки и анализа будем рассматривать представление изображения как трёхмерного массива чисел,
имеющего ширину, количество столбцов, и высоту, количество строк, равными ширине и высоте изображения соответственно.
На каждой позиции по ширине и высоте будет находится вектор из трех целых чисел, из промежутка [0, 255], что
соответствует RGB модели представления цвета пикселя изображения.
В таком случае сегментацией изображения будет являться отображение каждого RGB вектора в некоторое целое число.
Это число соответствует идентификатору некоторого класса.
При применение такого отображения ко всему изображению получается двумерный массив, ширина и высота которого
соответствуют таковым у исходного изображения.
Подобный двумерный массив будет разделять изображение на регионы по обозначенному признаку и называться сегментационной маской.
Сегментацию возможно рассматривать как попиксельную классификацию объектов.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/example_segmentation.png}
    \caption{Общий вид сегментации на примере данных датасета COCO}
    \label{fig:seg_example}
\end{figure}

Отметим, что описанное выше отображение может обладать относительно простой природой и учитывать только значение пикселя в конкретной позиции,
так и более сложной структурой, использующей информацию о распределении цветов во всем изображении, положении пикселя на изображении и
свойствах соседних пикселей, непосредственно соседствующих с обозреваемым значением или отступающих от него на заданное смещение~\autocite{liu2018recent}.
На~\ref{fig:seg_example} показан общий вид задачи сегментации изображения.

\subsection{Выделение неба в рамках задачи сегментации}

Описанная в введение задача выделения региона неба на входном изображении может быть рассмотрена как задача сегментации.
Так как в данном случае результирующих классов всегда два - класс принадлежности и обратный ему -, то имеется более узкий случай сегментации - бинарная.
Итоговая маска будет содержать только значения 0 и 1, представляя собой однобитовое бинарное изображение, что можно считать вырожденным полутоновым.

Таким образом, решение задачи выделения неба сводится к нахождению отображения из вектора цветов для каждого пикселя в целое число из промежутка [0, 1].
Данное отображение возможно получить как алгоритмами машинного зрения, так и с помощью использования моделей глубоких сверточных нейронных сетей.
В данной работе приводится решение методом нейронных сетей, при этом алгоритмы компьютерного зрения используются для корректировки полученной маски.
Под корректировкой здесь понимается обнаружение и удаление ложноположительных регионов неба небольшой площади.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/sky_segmentation.png}
    \caption{Пример, демонстрирующий работу алгоритма}
    \label{fig:sky_seg}
\end{figure}

Практическое применение подобного решения можно найти в пользовательских приложениях эстетической обработки пейзажных фотографий для смартфонов,
в автоматических системах мониторинга воздушного пространства, при извлечении семантической информации высшего порядка для использования в иных методах анализа
и обработки изображений~\autocite{7415405}.

\section{Обзор предметной области}

Задача семантического анализа изображений имеет широкое применение при решении различных прикладных и исследовательских
проблем~\autocite{maier2018gentle}~\autocite{pan2019image}~\autocite{stabinger2020evaluating}~\autocite{li2015brief},
в связи с чем активно изучается.
Сегментации изображений, в частности, нашли применения в таких областях как проведение хирургических операций,
автопилотируемый транспорт, автоматизированное картографирование местности~\autocite{liu2018recent}.
Ниже приведен краткий обзор исследований, темы которых связаны с поставленной задачей.
Результаты этих исследований в разной степени использовались для построения решения.

\subsection{Сегментация изображений}

До начала активного применения глубоких нейронных сетей в задачах сегментации использовались методы компьютерного зрения,
основанные на применении порогов бинаризации для полутоновых изображений, выявлении признаков,
кластеризации методом k-средних~\autocite{10.5555/1888028.1888043}~\autocite{10.5555/540298}~\autocite{inproceedings}.
Каждый из этих подходов имеет свои преимущества, метод бинарной сегментации полутоновых изображений до сих пор успешно применяется
в области анализа медицинских данных~\autocite{bookMedicalImages}.
Но применение данных подходов к задаче выделения границы между объектами путем сегментации показало худшие результаты в сравнении с FCN,
полностью сверточными глубокими сетями~\autocite{7966418}.

Современные решения задачи сегментации в различных областях зачастую опираются на применение нейронных сетей~\autocite{feng2019deep}.
Наиболее распространёнными архитектурами являются Unet, DeepLab, RefineNet~\autocite{ronneberger2015unet}~\autocite{chen2016deeplab}~\autocite{lin2016refinenet}.
Имеются исследования применения архитектуры RefineNet для определения региона неба на датасете SkyFinder~\autocite{place2017segmenting}.

\subsection{Способы регуляризации}

Помимо специализированных решений задачи сегментации, были рассмотрены также общие методики, применяемые для обучения глубоких нейронных сетей.
При высокой сложности модели, в процессе обучения она может начать отражать в ответах шум в тренировочных данных~\autocite{salman2019overfitting}~\autocite{ghojogh2019theory}.
Данное явление называется переобучением, overfitting.
С целью снизить вероятность его проявление применяются разнообразные техники регуляризации: dropout, нормализация значений между слоями сети,
настройка гиперпараметров процесса обучения~\autocite{smith2018disciplined}~\autocite{labach2019survey}~\autocite{ioffe2015batch}.

\section{Метод решения}

Конечное решение задачи сегментации имеет комплексное строение.
Изображение, поступающее на вход решающему алгоритму, обрабатывается ИНС.
Результатом такого применения является двумерный массив пар.
Каждое значение в паре обозначает вероятность принадлежности одному из двух классов.
Для получения сегментационной маски индекс максимального из двух значений расценивается как идентификатор класса: 1 для региона неба, 0 - обратный ему.
В ходе экспериментов было выявлено наличие артефактов в результатах классификации.
Для части изображений имелись ложноположительные регионы неба небольшой площади.
Для их устранения последовательно применялись алгоритмы FindCounters и DrawCounters из состава библиотеки OpenCV.

Для обучения сети использовался датасет SkyFinder.
Для улучшения показателя IoU на целевом домене изображений использовалась техника Unsupervised Domain Adaptation.
Это позволило уменьшить количество ложноположительных и ложноотрицательных регионов без дополнительной разметки обучающий выборки из фотографий,
сделанных на мобильные устройства.

\subsection{Глубокая сверточная сеть}

Как было отмечено выше, текущие исследования указывают на преимущества глубоких сверточных сетей в задачах семантического анализа
перед классическими алгоритмами компьютерного зрения.
Глубокими сверточными сетями называют подмножество искусственных нейронных сетей, все полносвязные слои которых заменены сверточными.

Архитектура сети для решения задачи сегментации представляется двумя частями.
Выделение признаков, downsampling path, и генерализация результатов выделения, upsampling path.
Для решения проблемы потери информации в сверточных слоях, карты признаков с некоторых уровней нисходящей части объединяют с противоположными входами восходящей части.
На~\ref{fig:net_arch_common} приведена общая схема сети для задач сегментации.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/net_arch.png}
    \caption{Общий вид глубокой сверточной сети для задачи сегментации}
    \label{fig:net_arch_common}
\end{figure}

В нисходящей части используются сверточные слои (отмечены желтым цветом на~\ref{fig:net_arch_common}),
слои с выбором наибольшего значения по ядру - max pooling (отмечены красным цветом на~\ref{fig:net_arch_common}).
На сверточных слоях к входным данным применяются ядра свертки.
Количество ядер определяет для слоя количество выходных карт признаков.
Выходные карты признаков подаются на вход следующему слою.
К выходным картам применяется функция активации (отмечены оранжевым цветом на~\ref{fig:net_arch_common}).
Значения в ядрах свертки являются обучаемыми параметрами сети.
Ниже приведена формула для простого случая двумерного входного массива и двумерного ядра свертки~\eqref{eq:1} при единичном шаге.

\begin{equation}
    \label{eq:1}
    G[m, n] = (f*h)[m, n] = \sum_{j}{\sum_{k}{h[j, k]f[m + j, n + k]}}
\end{equation}

где f - входной массив данных, h - ядро свертки, G - выходная карта признаков.

Размеры каждой карты определяются размерами входных данных, размерами ядра, размером добавочного отступа по краям массива данных и сдвигом,
на которое ядро смещается по массиву~\eqref{eq:2}.

\begin{equation}
    \label{eq:2}
    output = \frac{input + 2 * p - k}{s} + 1
\end{equation}

где output - размеры выходной карты признаков, input - размеры входного массива данных, p - величина отступа, добавляемого к краям массива (padding),
k - размеры ядра свертки, s - сдвиг ядра.

В слоях с выбором наибольшего значения ядро определяет только размеры окна, в котором выбирается максимальный элемент~\eqref{eq:3}.
Операции сложения и умножения на этом слое не используются.

\begin{equation}
    \label{eq:3}
    G_{i, j} = \max_{(k, l) \in N}{F_{i + k, j + l}}
\end{equation}

где

\begin{equation}
    \label{eq:4}
    N = \{0, .. , \text{kernel size}\}
\end{equation}

G - выходная карта признаков, F - входной массив данных.

В качестве функции активации используется rectified linear unit, ReLU~\eqref{eq:5}.

\begin{equation}
    \label{eq:5}
    g(x) =
    \begin{cases}
        0 &x < 0 \\
        x &x \geq 0
    \end{cases}
\end{equation}

В upsampling части сети используются, помимо сверточных, транспонированные сверточные слои (отмечены синим цветом на~\ref{fig:net_arch_common}).
Прежде чем описать оператор транспонированной свертки, необходимо рассмотреть применение сверточного ядра к входным данным,
как произведение матриц.
Рассмотрим на примере ядра свертки размером $ 3 \times 3 $ и входного массива размером $ 4 \times 4 $.
Значение сдвига равно 1, дополнение отступом не используется.

$$
\setcounter{MaxMatrixCols}{20}
\small
\begin{equation}
    \label{eq:6}
    \begin{pmatrix}
         K_{0,0} & K_{0, 1} & K_{0, 2} & 0 & K_{1,0} & K_{1, 1} & K_{1, 2} & 0 & K_{2,0} & K_{2, 1} & K_{2, 2} & 0 & 0 & 0 & 0 & 0 \\
         0 & K_{0,0} & K_{0, 1} & K_{0, 2} & 0 & K_{1,0} & K_{1, 1} & K_{1, 2} & 0 & K_{2,0} & K_{2, 1} & K_{2, 2} & 0 & 0 & 0 & 0 \\
         0 & 0 & 0 & 0 & K_{0,0} & K_{0, 1} & K_{0, 2} & 0 & K_{1,0} & K_{1, 1} & K_{1, 2} & 0 & K_{2,0} & K_{2, 1} & K_{2, 2} & 0 \\
         0 & 0 & 0 & 0 & 0 & K_{0,0} & K_{0, 1} & K_{0, 2} & 0 & K_{1,0} & K_{1, 1} & K_{1, 2} & 0 & K_{2,0} & K_{2, 1} & K_{2, 2} \\
    \end{pmatrix}

\end{equation}

\small
\begin{equation}
    \label{eq:7}
    \begin{pmatrix}
         W_{0,0} & W_{0, 1} & W_{0, 2} & W_{0, 3} & W_{1,0} & W_{1, 1} & W_{1, 2} & W_{1, 3} & W_{2,0} & W_{2, 1} & W_{2, 2} & W_{2, 3} & W_{3,0} & W_{3, 1} & W_{3, 2} & W_{3, 3} \\
    \end{pmatrix}

\end{equation}
\normalsize
$$

В~\eqref{eq:6} введена матрица K, ненулевые элементы которой представлены значениями из ядра свертки.
$ K_{i,j} $ - элемент, стоящий в ядре на позиции i, j.
В~\eqref{eq:7} введена матрица I, полученная путем перекомпоновки входного массива данных в вектор по строкам.
Тогда карту признаков G размером $ 2 \times 2 $ можно получить путем умножения матрицы $ K $ на $ I^{T} $.

$$
\setcounter{MaxMatrixCols}{1}
\small
\begin{equation}
    \label{eq:8}
    K * I^{T} =
    \begin{pmatrix}
        & G_{0, 0} & \\
        & G_{0, 1} & \\
        & G_{1, 0} & \\
        & G_{1, 1} & \\
    \end{pmatrix}
\end{equation}
$$

Чтобы из~\eqref{eq:1} получить~\eqref{eq:8} необходимо записать матричное произведение, избавиться от нулевых слагаемых и объединить оставшиеся под знаки суммы по индексу.

Введем транспонированную свертку для входных данных F размером $ 2 \times 2 $, ядра свертки H $ 3 \times 3 $ и выходной карты признаков G $ 4 \times 4 $,
как произведение $K^{T}$, полученной из H аналогично~\eqref{eq:6}, на $F_{0}^{T}$, полученный из F аналогично~\eqref{eq:7}.

$$
\setcounter{MaxMatrixCols}{1}
\small
\begin{equation}
    \label{eq:9}
    K^{T} * F_{0}^{T} =
    \begin{pmatrix}
         G_{0, 0}  \\
         G_{0, 1}  \\
         G_{0, 2}  \\
         G_{0, 3}  \\
         G_{1, 0}  \\
         G_{1, 1}  \\
         G_{1, 2}  \\
         G_{1, 3}  \\
         G_{2, 0}  \\
         G_{2, 1}  \\
         G_{2, 2}  \\
         G_{2, 3}  \\
         G_{3, 0}  \\
         G_{3, 1}  \\
         G_{3, 2}  \\
         G_{3, 3}  \\
    \end{pmatrix}
\end{equation}
$$

Таким образом~\eqref{eq:9} позволяет восстанавливать исходное количество пикселей для их классификации по выделенным признакам~\autocite{dumoulin2016guide}.
Отметим здесь, что сверточные слои в восходящей части не уменьшают размеры данных по высоте и ширине за счёт использования паддинга.

После выходного слоя размеры массива данных равняются $ N \times M \times C $, где $N$, $M$ - размеры исходного изображения, а $C$ - количество классов.
К полученным данным применяется логистическая функция, обобщённая на многомерный случай, softmax~\eqref{eq:10}.
Вычисления осуществляются для каждой позиции $ [n, m] $ по размерности $C$\@.

\begin{equation}
    \label{eq:10}
    Softmax(x_{i}) = \frac{{}e^{x_{i}}}{\sum_{j}e^{x_{j}}}
\end{equation}

В результате каждый вектор $\bar{v}$ из массива данных по размерности $C$ обладает следующими свойствами:

\begin{itemize}
    \item $v_{i} \in [0,1] \forall i \in [0, C]$ \\
    \item $\sum_{i=0}^{C} v_{i}=1$
\end{itemize}

Ниже приведен (~\ref{fig:softmax_debug_info}) отладочный вывод данных до и после softmax для программы, реализующей обучения глубокой сверточной сети с ResNet34 блоком в качестве downsampling части
и LinkNet в качестве upsampling.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/softmax_debug_info.png}
    \caption{Отладочная информация с визуализацией}
    \label{fig:softmax_debug_info}
\end{figure}

\subsection{Регуляризация на уровне архитектуры}

Как было отмечено в части обзора решений, при обучении сети может возникнуть overfitting.
Состояние модели, в котором она демонстрирует значительно более высокие метрики качества на тренировочных данных,
чем на тестовых.
Причиной такого поведения может быть запоминание шумов данных.
К ним могут быть отнесены статистические выбросы, неравномерное представление классов в выборке, фактическая природа данных.
В частности, при преобладании определённого признака в данных вероятно проявление ковариантного сдвига по признаку (Covariate Shift)~\autocite{covariateShift}.
Подобное смещение приводит к смещению на уровне внутренних слоев.
Для предотвращения влияния данные между слоями приводят к нормализованному состоянию~\eqref{eq:11}.
Нормирование происходит по пакету, batch.

\begin{equation}
    \centering
    \item $1.~~\mu_{\mathcal B} & = & \frac1m \sum_{i = 1}^m x_i $
    \item $2.~~\sigma^2_{\mathcal B} & = & \frac1m \sum_{i=1}^m (x_i - \mu_{\mathcal B})^2 $
    \item $3.~~\hat x_i & = & \frac{x_i - \mu_{\mathcal B}}{\sqrt{\sigma_{\mathcal B}^2 + \epsilon}} $
    \item $4.~~\mathrm{BN}_{\gamma,\beta}(x_i) & = & \gamma \hat x_i + \beta $
    \label{eq:11}
\end{equation}

Здесь $x_{i} \in X$, где $X$ - текущий пакет входных данных.
Этапы 11.1, 11.2, 11.3 применяются только на этапе обучения сети.
Параметры $\gamma$ и $\beta$ являются обучаемыми.
При инференсе сети они обеспечивают соответствие среднего и смещения для входных данных аналогичными показателями
тренировочных пакетов.
На~\ref{fig:batch_norm} продемонстрировано сравнение процессов обучения с и без описанной техники.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/batch_normalization.png}
    \caption{Улучшение сходимости нормализацией}
    \label{fig:batch_norm}
\end{figure}

\subsection{Выделение признаков, downsampling}

Для выделение признаков рассматривались сети архитектуры ResNet.
Отличительной чертой данной архитектуры являются residual block и наличие skip connection.
В состав одного блока последовательно входят:

\begin{enumerate}
    \item Сверточный слой с паддингом
    \item Нормализация по пакету
    \item Активационная функция
    \item Сверточный слой с паддингом
    \item Нормализация по пакету
\end{enumerate}

Результат блока объединяется с входными данными.
Такое решение позволяет предотвратить затухание градиента при обратном распространении ошибки~\autocite{he2015deep}.

Для снижения размеров массива данных в архитектуре ResNet используются блоки, сочетающие в себе сверточный слой
с ядром $1 \times 1$, без паддинга и сдвигом в 2 и нормализацию по пакету.

В итоговое решение в качестве downsampling path вошла архитектура ResNet34.
Она обладает меньшим количеством тренируемых параметров в сравнении с ResNet50, ResNet101, ResNet152.
При этом демонстрируется достаточное значение метрики качества.

\section{Данные}

Эксперименты с обучением модели ИНС проводились на двух наборах данных: SkyFinder и набор из фотографий, сделанных на камеры смартфонов,
с синтетической разметкой в объединении с данными из SkyFinder.

\subsection{Датасет SkyFinder}

SkyFinder представляет собой набор из 90.000 фотографий~\autocite{mihail2016sky}.
Все фотографии сделаны на статичные веб-камеры, расположенные вне зданий.
В верхней части изображений преобладает регион неба.
Средний процент пикселей относящихся к классу принадлежности равен 41 со стандартным отклонением в 16 процентов.
Изображения покрывают широкий диапазон освещённости и погодных условий, что препятствует переобучению на конкретных значениях.
Для каждого изображения имеется размеченная бинарная маска с описанным в постановке задачи свойством: 1 обозначает класс принадлежности, 0 - обратный ему.

\subsection{Датасет с синтетической разметкой}

\Conc

% Печать списка литературы (библиографии)
\printbibliography[%{}
    heading=bibintoc%
%,title=Библиография % если хочется это слово
]
% Файл со списком литературы: biblio.bib
% Подробно по оформлению библиографии:
% см. документацию к пакету biblatex-gost
% http://ctan.mirrorcatalogs.com/macros/latex/exptl/biblatex-contrib/biblatex-gost/doc/biblatex-gost.pdf
% и огромное количество примеров там же:
% http://mirror.macomnet.net/pub/CTAN/macros/latex/contrib/biblatex-contrib/biblatex-gost/doc/biblatex-gost-examples.pdf

\end{document}
